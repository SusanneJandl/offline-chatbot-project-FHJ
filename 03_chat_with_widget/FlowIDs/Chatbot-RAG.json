{"name": "Chatbot-RAG", "description": "creates Vector Store", "icon": null, "icon_bg_color": null, "gradient": null, "data": {"nodes": [{"id": "RecursiveCharacterTextSplitter-Pga8C", "type": "genericNode", "position": {"x": 512, "y": 41.3125}, "data": {"type": "RecursiveCharacterTextSplitter", "node": {"template": {"_type": "Component", "data_input": {"tool_mode": false, "trace_as_metadata": true, "list": false, "trace_as_input": true, "required": false, "placeholder": "", "show": true, "name": "data_input", "value": "", "display_name": "Input", "advanced": false, "input_types": ["Document", "Data"], "dynamic": false, "info": "The texts to split.", "title_case": false, "type": "other", "_input_type": "DataInput"}, "chunk_overlap": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "chunk_overlap", "value": 20, "display_name": "Chunk Overlap", "advanced": false, "dynamic": false, "info": "The amount of overlap between chunks.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "chunk_size": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "chunk_size", "value": 100, "display_name": "Chunk Size", "advanced": false, "dynamic": false, "info": "The maximum length of each chunk.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "from typing import Any\n\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter, TextSplitter\n\nfrom langflow.base.textsplitters.model import LCTextSplitterComponent\nfrom langflow.inputs.inputs import DataInput, IntInput, MessageTextInput\nfrom langflow.utils.util import unescape_string\n\n\nclass RecursiveCharacterTextSplitterComponent(LCTextSplitterComponent):\n    display_name: str = \"Recursive Character Text Splitter\"\n    description: str = \"Split text trying to keep all related text together.\"\n    documentation: str = \"https://docs.langflow.org/components/text-splitters#recursivecharactertextsplitter\"\n    name = \"RecursiveCharacterTextSplitter\"\n    icon = \"LangChain\"\n\n    inputs = [\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum length of each chunk.\",\n            value=1000,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"The amount of overlap between chunks.\",\n            value=200,\n        ),\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Input\",\n            info=\"The texts to split.\",\n            input_types=[\"Document\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"separators\",\n            display_name=\"Separators\",\n            info='The characters to split on.\\nIf left empty defaults to [\"\\\\n\\\\n\", \"\\\\n\", \" \", \"\"].',\n            is_list=True,\n        ),\n    ]\n\n    def get_data_input(self) -> Any:\n        return self.data_input\n\n    def build_text_splitter(self) -> TextSplitter:\n        if not self.separators:\n            separators: list[str] | None = None\n        else:\n            # check if the separators list has escaped characters\n            # if there are escaped characters, unescape them\n            separators = [unescape_string(x) for x in self.separators]\n\n        return RecursiveCharacterTextSplitter(\n            separators=separators,\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n        )\n", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "separators": {"tool_mode": false, "trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": true, "required": false, "placeholder": "", "show": true, "name": "separators", "value": "", "display_name": "Separators", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "The characters to split on.\nIf left empty defaults to [\"\\n\\n\", \"\\n\", \" \", \"\"].", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}}, "description": "Split text trying to keep all related text together.", "icon": "LangChain", "base_classes": ["Data"], "display_name": "Recursive Character Text Splitter", "documentation": "https://docs.langflow.org/components/text-splitters#recursivecharactertextsplitter", "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Data"], "selected": "Data", "name": "data", "display_name": "Data", "method": "transform_data", "value": "__UNDEFINED__", "cache": true, "required_inputs": []}], "field_order": ["chunk_size", "chunk_overlap", "data_input", "separators"], "beta": false, "legacy": false, "edited": false, "metadata": {}, "tool_mode": false, "lf_version": "1.1.1"}, "id": "RecursiveCharacterTextSplitter-Pga8C"}, "selected": false, "width": 320, "height": 474, "positionAbsolute": {"x": 512, "y": 41.3125}, "dragging": false}, {"id": "OllamaEmbeddings-pPxTh", "type": "genericNode", "position": {"x": 429.889630010747, "y": 731.541322720381}, "data": {"type": "OllamaEmbeddings", "node": {"template": {"_type": "Component", "base_url": {"tool_mode": false, "trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "base_url", "value": "http://localhost:11434", "display_name": "Ollama Base URL", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "from langchain_ollama import OllamaEmbeddings\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import MessageTextInput, Output\n\n\nclass OllamaEmbeddingsComponent(LCModelComponent):\n    display_name: str = \"Ollama Embeddings\"\n    description: str = \"Generate embeddings using Ollama models.\"\n    documentation = \"https://python.langchain.com/docs/integrations/text_embedding/ollama\"\n    icon = \"Ollama\"\n    name = \"OllamaEmbeddings\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"model\",\n            display_name=\"Ollama Model\",\n            value=\"nomic-embed-text\",\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"Ollama Base URL\",\n            value=\"http://localhost:11434\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            output = OllamaEmbeddings(model=self.model, base_url=self.base_url)\n        except Exception as e:\n            msg = \"Could not connect to Ollama API.\"\n            raise ValueError(msg) from e\n        return output\n", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "model": {"tool_mode": false, "trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "model", "value": "all-minilm:22m", "display_name": "Ollama Model", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}}, "description": "Generate embeddings using Ollama models.", "icon": "Ollama", "base_classes": ["Embeddings"], "display_name": "Ollama Embeddings", "documentation": "https://python.langchain.com/docs/integrations/text_embedding/ollama", "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Embeddings"], "selected": "Embeddings", "name": "embeddings", "display_name": "Embeddings", "method": "build_embeddings", "value": "__UNDEFINED__", "cache": true}], "field_order": ["model", "base_url"], "beta": false, "legacy": false, "edited": false, "metadata": {}, "tool_mode": false, "lf_version": "1.1.1"}, "id": "OllamaEmbeddings-pPxTh"}, "selected": false, "width": 320, "height": 320, "dragging": false}, {"id": "Directory-Np1nB", "type": "genericNode", "position": {"x": -276.50068847069707, "y": 475.7447026366284}, "data": {"type": "Directory", "node": {"template": {"_type": "Component", "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "from langflow.base.data.utils import TEXT_FILE_TYPES, parallel_load_data, parse_text_file_to_data, retrieve_file_paths\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, IntInput, MessageTextInput\nfrom langflow.schema import Data\nfrom langflow.template import Output\n\n\nclass DirectoryComponent(Component):\n    display_name = \"Directory\"\n    description = \"Recursively load files from a directory.\"\n    icon = \"folder\"\n    name = \"Directory\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"path\",\n            display_name=\"Path\",\n            info=\"Path to the directory to load files from.\",\n        ),\n        MessageTextInput(\n            name=\"types\",\n            display_name=\"Types\",\n            info=\"File types to load. Leave empty to load all default supported types.\",\n            is_list=True,\n        ),\n        IntInput(\n            name=\"depth\",\n            display_name=\"Depth\",\n            info=\"Depth to search for files.\",\n            value=0,\n        ),\n        IntInput(\n            name=\"max_concurrency\",\n            display_name=\"Max Concurrency\",\n            advanced=True,\n            info=\"Maximum concurrency for loading files.\",\n            value=2,\n        ),\n        BoolInput(\n            name=\"load_hidden\",\n            display_name=\"Load Hidden\",\n            advanced=True,\n            info=\"If true, hidden files will be loaded.\",\n        ),\n        BoolInput(\n            name=\"recursive\",\n            display_name=\"Recursive\",\n            advanced=True,\n            info=\"If true, the search will be recursive.\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"Use Multithreading\",\n            advanced=True,\n            info=\"If true, multithreading will be used.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"load_directory\"),\n    ]\n\n    def load_directory(self) -> list[Data]:\n        path = self.path\n        types = (\n            self.types if self.types and self.types != [\"\"] else TEXT_FILE_TYPES\n        )  # self.types is already a list due to is_list=True\n        depth = self.depth\n        max_concurrency = self.max_concurrency\n        load_hidden = self.load_hidden\n        recursive = self.recursive\n        silent_errors = self.silent_errors\n        use_multithreading = self.use_multithreading\n\n        resolved_path = self.resolve_path(path)\n        file_paths = retrieve_file_paths(\n            resolved_path, load_hidden=load_hidden, recursive=recursive, depth=depth, types=types\n        )\n\n        if types:\n            file_paths = [fp for fp in file_paths if any(fp.endswith(ext) for ext in types)]\n\n        loaded_data = []\n\n        if use_multithreading:\n            loaded_data = parallel_load_data(file_paths, silent_errors=silent_errors, max_concurrency=max_concurrency)\n        else:\n            loaded_data = [parse_text_file_to_data(file_path, silent_errors=silent_errors) for file_path in file_paths]\n        loaded_data = list(filter(None, loaded_data))\n        self.status = loaded_data\n        return loaded_data  # type: ignore[return-value]\n", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "depth": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "depth", "value": 0, "display_name": "Depth", "advanced": false, "dynamic": false, "info": "Depth to search for files.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "load_hidden": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "load_hidden", "value": false, "display_name": "Load Hidden", "advanced": true, "dynamic": false, "info": "If true, hidden files will be loaded.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}, "max_concurrency": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "max_concurrency", "value": 2, "display_name": "Max Concurrency", "advanced": true, "dynamic": false, "info": "Maximum concurrency for loading files.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "path": {"tool_mode": false, "trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "path", "value": "C:\\Users\\susan\\Documents\\repos\\offline_chatbot\\Final_Project\\InfoSource\\Dogs", "display_name": "Path", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "Path to the directory to load files from.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "recursive": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "recursive", "value": false, "display_name": "Recursive", "advanced": true, "dynamic": false, "info": "If true, the search will be recursive.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}, "silent_errors": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "silent_errors", "value": false, "display_name": "Silent Errors", "advanced": true, "dynamic": false, "info": "If true, errors will not raise an exception.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}, "types": {"tool_mode": false, "trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": true, "required": false, "placeholder": "", "show": true, "name": "types", "value": "", "display_name": "Types", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "File types to load. Leave empty to load all default supported types.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "use_multithreading": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "use_multithreading", "value": false, "display_name": "Use Multithreading", "advanced": true, "dynamic": false, "info": "If true, multithreading will be used.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}}, "description": "Recursively load files from a directory.", "icon": "folder", "base_classes": ["Data"], "display_name": "Directory", "documentation": "", "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Data"], "selected": "Data", "name": "data", "display_name": "Data", "method": "load_directory", "value": "__UNDEFINED__", "cache": true}], "field_order": ["path", "types", "depth", "max_concurrency", "load_hidden", "recursive", "silent_errors", "use_multithreading"], "beta": false, "legacy": false, "edited": false, "metadata": {}, "tool_mode": false, "lf_version": "1.1.1"}, "id": "Directory-Np1nB"}, "selected": false, "width": 320, "height": 406, "dragging": false, "positionAbsolute": {"x": -276.50068847069707, "y": 475.7447026366284}}, {"id": "FAISS-wGIAG", "type": "genericNode", "position": {"x": 1019.3744144265618, "y": 277.73033367184087}, "data": {"node": {"template": {"_type": "Component", "embedding": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "embedding", "value": "", "display_name": "Embedding", "advanced": false, "input_types": ["Embeddings"], "dynamic": false, "info": "", "title_case": false, "type": "other", "_input_type": "HandleInput"}, "ingest_data": {"tool_mode": false, "trace_as_metadata": true, "list": true, "trace_as_input": true, "required": false, "placeholder": "", "show": true, "name": "ingest_data", "value": "", "display_name": "Ingest Data", "advanced": false, "input_types": ["Data"], "dynamic": false, "info": "", "title_case": false, "type": "other", "_input_type": "DataInput"}, "allow_dangerous_deserialization": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "allow_dangerous_deserialization", "value": true, "display_name": "Allow Dangerous Deserialization", "advanced": true, "dynamic": false, "info": "Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}, "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "from langchain_community.vectorstores import FAISS\nfrom loguru import logger\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import BoolInput, DataInput, HandleInput, IntInput, MultilineInput, StrInput\nfrom langflow.schema import Data\n\n\nclass FaissVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"FAISS Vector Store with search capabilities.\"\"\"\n\n    display_name: str = \"FAISS\"\n    description: str = \"FAISS Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss\"\n    name = \"FAISS\"\n    icon = \"FAISS\"\n\n    inputs = [\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            value=\"langflow_index\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n            info=\"Path to save the FAISS index. It will be relative to where Langflow is running.\",\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        BoolInput(\n            name=\"allow_dangerous_deserialization\",\n            display_name=\"Allow Dangerous Deserialization\",\n            info=\"Set to True to allow loading pickle files from untrusted sources. \"\n            \"Only enable this if you trust the source of the data.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> FAISS:\n        \"\"\"Builds the FAISS object.\"\"\"\n        if not self.persist_directory:\n            msg = \"Folder path is required to save the FAISS index.\"\n            raise ValueError(msg)\n        path = self.resolve_path(self.persist_directory)\n\n        documents = []\n\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        faiss = FAISS.from_documents(documents=documents, embedding=self.embedding)\n        faiss.save_local(str(path), self.index_name)\n\n        return faiss\n\n    def search_documents(self) -> list[Data]:\n        \"\"\"Search for documents in the FAISS vector store.\"\"\"\n        if not self.persist_directory:\n            msg = \"Folder path is required to load the FAISS index.\"\n            raise ValueError(msg)\n        path = self.resolve_path(self.persist_directory)\n\n        vector_store = FAISS.load_local(\n            folder_path=path,\n            embeddings=self.embedding,\n            index_name=self.index_name,\n            allow_dangerous_deserialization=self.allow_dangerous_deserialization,\n        )\n\n        if not vector_store:\n            msg = \"Failed to load the FAISS index.\"\n            raise ValueError(msg)\n\n        logger.debug(f\"Search input: {self.search_query}\")\n        logger.debug(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            logger.debug(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            logger.debug(f\"Converted documents to data: {len(data)}\")\n            logger.debug(data)\n            return data  # Return the search results data\n        logger.debug(\"No search input provided. Skipping search.\")\n        return []\n", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "index_name": {"trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "index_name", "value": "langflow_vs", "display_name": "Index Name", "advanced": false, "dynamic": false, "info": "", "title_case": false, "type": "str", "_input_type": "StrInput"}, "number_of_results": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "number_of_results", "value": 4, "display_name": "Number of Results", "advanced": true, "dynamic": false, "info": "Number of results to return.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "persist_directory": {"trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "persist_directory", "value": "C:\\Users\\susan\\Documents\\repos\\offline_chatbot\\Final_Project\\VectorStores\\langflow", "display_name": "Persist Directory", "advanced": false, "dynamic": false, "info": "Path to save the FAISS index. It will be relative to where Langflow is running.", "title_case": false, "type": "str", "_input_type": "StrInput"}, "search_query": {"tool_mode": false, "trace_as_input": true, "multiline": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "search_query", "value": "", "display_name": "Search Query", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "", "title_case": false, "type": "str", "_input_type": "MultilineInput"}}, "description": "FAISS Vector Store with search capabilities", "icon": "FAISS", "base_classes": ["Data", "Retriever"], "display_name": "FAISS", "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss", "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Retriever"], "selected": "Retriever", "name": "base_retriever", "display_name": "Retriever", "method": "build_base_retriever", "value": "__UNDEFINED__", "cache": true, "required_inputs": []}, {"types": ["Data"], "selected": "Data", "name": "search_results", "display_name": "Search Results", "method": "search_documents", "value": "__UNDEFINED__", "cache": true, "required_inputs": []}], "field_order": ["index_name", "persist_directory", "search_query", "ingest_data", "allow_dangerous_deserialization", "embedding", "number_of_results"], "beta": false, "legacy": false, "edited": false, "metadata": {}, "tool_mode": false, "lf_version": "1.1.1"}, "type": "FAISS", "id": "FAISS-wGIAG"}, "selected": true, "width": 320, "height": 550, "positionAbsolute": {"x": 1019.3744144265618, "y": 277.73033367184087}, "dragging": false}], "edges": [{"source": "Directory-Np1nB", "sourceHandle": "{\u0153dataType\u0153:\u0153Directory\u0153,\u0153id\u0153:\u0153Directory-Np1nB\u0153,\u0153name\u0153:\u0153data\u0153,\u0153output_types\u0153:[\u0153Data\u0153]}", "target": "RecursiveCharacterTextSplitter-Pga8C", "targetHandle": "{\u0153fieldName\u0153:\u0153data_input\u0153,\u0153id\u0153:\u0153RecursiveCharacterTextSplitter-Pga8C\u0153,\u0153inputTypes\u0153:[\u0153Document\u0153,\u0153Data\u0153],\u0153type\u0153:\u0153other\u0153}", "data": {"targetHandle": {"fieldName": "data_input", "id": "RecursiveCharacterTextSplitter-Pga8C", "inputTypes": ["Document", "Data"], "type": "other"}, "sourceHandle": {"dataType": "Directory", "id": "Directory-Np1nB", "name": "data", "output_types": ["Data"]}}, "id": "reactflow__edge-Directory-Np1nB{\u0153dataType\u0153:\u0153Directory\u0153,\u0153id\u0153:\u0153Directory-Np1nB\u0153,\u0153name\u0153:\u0153data\u0153,\u0153output_types\u0153:[\u0153Data\u0153]}-RecursiveCharacterTextSplitter-Pga8C{\u0153fieldName\u0153:\u0153data_input\u0153,\u0153id\u0153:\u0153RecursiveCharacterTextSplitter-Pga8C\u0153,\u0153inputTypes\u0153:[\u0153Document\u0153,\u0153Data\u0153],\u0153type\u0153:\u0153other\u0153}", "animated": false, "className": ""}, {"source": "RecursiveCharacterTextSplitter-Pga8C", "sourceHandle": "{\u0153dataType\u0153:\u0153RecursiveCharacterTextSplitter\u0153,\u0153id\u0153:\u0153RecursiveCharacterTextSplitter-Pga8C\u0153,\u0153name\u0153:\u0153data\u0153,\u0153output_types\u0153:[\u0153Data\u0153]}", "target": "FAISS-wGIAG", "targetHandle": "{\u0153fieldName\u0153:\u0153ingest_data\u0153,\u0153id\u0153:\u0153FAISS-wGIAG\u0153,\u0153inputTypes\u0153:[\u0153Data\u0153],\u0153type\u0153:\u0153other\u0153}", "data": {"targetHandle": {"fieldName": "ingest_data", "id": "FAISS-wGIAG", "inputTypes": ["Data"], "type": "other"}, "sourceHandle": {"dataType": "RecursiveCharacterTextSplitter", "id": "RecursiveCharacterTextSplitter-Pga8C", "name": "data", "output_types": ["Data"]}}, "id": "reactflow__edge-RecursiveCharacterTextSplitter-Pga8C{\u0153dataType\u0153:\u0153RecursiveCharacterTextSplitter\u0153,\u0153id\u0153:\u0153RecursiveCharacterTextSplitter-Pga8C\u0153,\u0153name\u0153:\u0153data\u0153,\u0153output_types\u0153:[\u0153Data\u0153]}-FAISS-wGIAG{\u0153fieldName\u0153:\u0153ingest_data\u0153,\u0153id\u0153:\u0153FAISS-wGIAG\u0153,\u0153inputTypes\u0153:[\u0153Data\u0153],\u0153type\u0153:\u0153other\u0153}", "className": "", "animated": false}, {"source": "OllamaEmbeddings-pPxTh", "sourceHandle": "{\u0153dataType\u0153:\u0153OllamaEmbeddings\u0153,\u0153id\u0153:\u0153OllamaEmbeddings-pPxTh\u0153,\u0153name\u0153:\u0153embeddings\u0153,\u0153output_types\u0153:[\u0153Embeddings\u0153]}", "target": "FAISS-wGIAG", "targetHandle": "{\u0153fieldName\u0153:\u0153embedding\u0153,\u0153id\u0153:\u0153FAISS-wGIAG\u0153,\u0153inputTypes\u0153:[\u0153Embeddings\u0153],\u0153type\u0153:\u0153other\u0153}", "data": {"targetHandle": {"fieldName": "embedding", "id": "FAISS-wGIAG", "inputTypes": ["Embeddings"], "type": "other"}, "sourceHandle": {"dataType": "OllamaEmbeddings", "id": "OllamaEmbeddings-pPxTh", "name": "embeddings", "output_types": ["Embeddings"]}}, "id": "reactflow__edge-OllamaEmbeddings-pPxTh{\u0153dataType\u0153:\u0153OllamaEmbeddings\u0153,\u0153id\u0153:\u0153OllamaEmbeddings-pPxTh\u0153,\u0153name\u0153:\u0153embeddings\u0153,\u0153output_types\u0153:[\u0153Embeddings\u0153]}-FAISS-wGIAG{\u0153fieldName\u0153:\u0153embedding\u0153,\u0153id\u0153:\u0153FAISS-wGIAG\u0153,\u0153inputTypes\u0153:[\u0153Embeddings\u0153],\u0153type\u0153:\u0153other\u0153}", "className": "", "animated": false}], "viewport": {"x": -422.33985788655923, "y": -124.3284308305989, "zoom": 0.9505923412206734}}, "is_component": false, "updated_at": "2024-12-28T07:36:04+00:00", "webhook": false, "endpoint_name": "rag", "tags": null, "id": "1ffcdb52-d3f3-4516-8252-9c971e346d42", "user_id": "ee2ab924-6c8f-402b-94f9-03dfe7fb6e1e", "folder_id": "de943c14-ac97-4afa-aee7-43500e2a68ce"}